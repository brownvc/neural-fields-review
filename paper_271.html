

<!DOCTYPE html>
<html lang="en">

  <head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
      integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

    <script src="https://code.jquery.com/jquery-3.6.0.min.js"
      integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
      integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
      integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
      integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>


    <!-- Library libs_ext -->
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>

    <script src="static/js/tagEditor/jquery.caret.min.js"></script>
    <script src="static/js/tagEditor/jquery.tag-editor.min.js"></script>


    <!-- Internal Libs -->
    <script src="static/js/data/api.js"></script>

    <!-- External CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
      integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link href="static/css/Lato.css" rel="stylesheet" />
    <link href="static/css/Exo.css" rel="stylesheet" />
    <link href="static/css/Cuprum.css" rel="stylesheet" />
    <link rel="stylesheet" href="static/css/main.css" />
    <!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css" />
    <link rel="stylesheet" href="static/css/lazy_load.css" />
    <link rel="stylesheet" href="static/css/typeahead.css" />

    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/daterangepicker/daterangepicker.min.js"></script>
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/daterangepicker/daterangepicker.css" />

    <title>Neural Fields: Advances in Neural Rendering</title>

    <link rel="icon" type="image/png" href="favicon.ico">

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GT7LEVW06Z"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());

      gtag('config', 'G-GT7LEVW06Z');
    </script>
    <!-- head block ends here-->
    
<meta name="citation_title" content="Advances in Neural Rendering" />


<meta name="citation_author" content="Ayush Tewari" />

<meta name="citation_author" content="Justus Thies" />

<meta name="citation_author" content="Ben Mildenhall" />

<meta name="citation_author" content="Pratul Srinivasan" />

<meta name="citation_author" content="Edgar Tretschk" />

<meta name="citation_author" content="Yifan Wang" />

<meta name="citation_author" content="Christoph Lassner" />

<meta name="citation_author" content="Vincent Sitzmann" />

<meta name="citation_author" content="Ricardo Martin-Brualla" />

<meta name="citation_author" content="Stephen Lombardi" />

<meta name="citation_author" content="Tomas Simon" />

<meta name="citation_author" content="Christian Theobalt" />

<meta name="citation_author" content="Matthias Niessner" />

<meta name="citation_author" content="Jonathan T. Barron" />

<meta name="citation_author" content="Gordon Wetzstein" />

<meta name="citation_author" content="Michael Zollhoefer" />

<meta name="citation_author" content="Vladislav Golyanik" />


<meta name="citation_abstract" content="Synthesizing photo-realistic images and videos is at the heart of computer graphics and has been the focus of decades of research. Traditionally, synthetic images of a scene are generated using rendering algorithms such as rasterization or ray tracing, which take specifically defined representations of geometry and material properties as input. Collectively, these inputs define the actual scene and what is rendered, and are referred to as the scene representation (where a scene consists of one or more objects). Example scene representations are triangle meshes with accompanied textures (e.g., created by an artist), point clouds (e.g., from a depth sensor), volumetric grids (e.g., from a CT scan), or implicit surface functions (e.g., truncated signed distance fields). The reconstruction of such a scene representation from observations using differentiable rendering losses is known as inverse graphics or inverse rendering. Neural rendering is closely related, and combines ideas from classical computer graphics and machine learning to create algorithms for synthesizing images from real-world observations. Neural rendering is a leap forward towards the goal of synthesizing photo-realistic image and video content. In recent years, we have seen immense progress in this field through hundreds of publications that show different ways to inject learnable components into the rendering pipeline. This state-of-the-art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene. In addition to methods that handle static scenes, we cover neural scene representations for modeling non-rigidly deforming objects..." />


<meta name="citation_keywords" content="2D Image Neural Fields" />

<meta name="citation_keywords" content="Image-Based Rendering" />

<meta name="citation_pdf_url" content="https://arxiv.org/pdf/2111.05849.pdf" />

<script type="text/javascript" src="static/js/vis/vis-network.min.js"></script>
<style>
    .red-hyper-link {
        color: #ED1C24 !important;
    }
</style>

  </head>

  <body>
    <!-- NAV -->
    
    <nav class="navbar sticky-top navbar-expand-lg navbar-light" style="background-color: #EFECE5;" id="main-nav">
      <div class="container">
        <a class="navbar-brand" href="index.html">
          <img class="logo" src="static/images/long_logo.png" style="width: 300px;"/>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
          aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
          <ul class="navbar-nav ml-auto">
            
            <li class="nav-item ">
              <a class="nav-link" href="index.html" style="font-family: 'Ubuntu', sans-serif;">Home</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="papers.html" style="font-family: 'Ubuntu', sans-serif;">Advanced Search</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="add_paper.html" style="font-family: 'Ubuntu', sans-serif;">Add Paper</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="join_us.html" style="font-family: 'Ubuntu', sans-serif;">Join Us</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="faq.html" style="font-family: 'Ubuntu', sans-serif;">FAQ</a>
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
    

    
    <!-- User Overrides -->

    
    <!-- top block ends here-->
    

    <div class="container">
      <!-- Tabs -->
      <div class="tabs">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3">
    <div class="card-header">
        <h2 class="card-title main-title text-center" style="color: black;">
            Advances in Neural Rendering
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?author=Ayush Tewari" target="_blank"
                data-tippy-content="See all papers authored by Ayush Tewari"
                class="text-muted filterByAuthorLink">Ayush Tewari</a>,
            
            <a href="papers.html?author=Justus Thies" target="_blank"
                data-tippy-content="See all papers authored by Justus Thies"
                class="text-muted filterByAuthorLink">Justus Thies</a>,
            
            <a href="papers.html?author=Ben Mildenhall" target="_blank"
                data-tippy-content="See all papers authored by Ben Mildenhall"
                class="text-muted filterByAuthorLink">Ben Mildenhall</a>,
            
            <a href="papers.html?author=Pratul Srinivasan" target="_blank"
                data-tippy-content="See all papers authored by Pratul Srinivasan"
                class="text-muted filterByAuthorLink">Pratul Srinivasan</a>,
            
            <a href="papers.html?author=Edgar Tretschk" target="_blank"
                data-tippy-content="See all papers authored by Edgar Tretschk"
                class="text-muted filterByAuthorLink">Edgar Tretschk</a>,
            
            <a href="papers.html?author=Yifan Wang" target="_blank"
                data-tippy-content="See all papers authored by Yifan Wang"
                class="text-muted filterByAuthorLink">Yifan Wang</a>,
            
            <a href="papers.html?author=Christoph Lassner" target="_blank"
                data-tippy-content="See all papers authored by Christoph Lassner"
                class="text-muted filterByAuthorLink">Christoph Lassner</a>,
            
            <a href="papers.html?author=Vincent Sitzmann" target="_blank"
                data-tippy-content="See all papers authored by Vincent Sitzmann"
                class="text-muted filterByAuthorLink">Vincent Sitzmann</a>,
            
            <a href="papers.html?author=Ricardo Martin-Brualla" target="_blank"
                data-tippy-content="See all papers authored by Ricardo Martin-Brualla"
                class="text-muted filterByAuthorLink">Ricardo Martin-Brualla</a>,
            
            <a href="papers.html?author=Stephen Lombardi" target="_blank"
                data-tippy-content="See all papers authored by Stephen Lombardi"
                class="text-muted filterByAuthorLink">Stephen Lombardi</a>,
            
            <a href="papers.html?author=Tomas Simon" target="_blank"
                data-tippy-content="See all papers authored by Tomas Simon"
                class="text-muted filterByAuthorLink">Tomas Simon</a>,
            
            <a href="papers.html?author=Christian Theobalt" target="_blank"
                data-tippy-content="See all papers authored by Christian Theobalt"
                class="text-muted filterByAuthorLink">Christian Theobalt</a>,
            
            <a href="papers.html?author=Matthias Niessner" target="_blank"
                data-tippy-content="See all papers authored by Matthias Niessner"
                class="text-muted filterByAuthorLink">Matthias Niessner</a>,
            
            <a href="papers.html?author=Jonathan T. Barron" target="_blank"
                data-tippy-content="See all papers authored by Jonathan T. Barron"
                class="text-muted filterByAuthorLink">Jonathan T. Barron</a>,
            
            <a href="papers.html?author=Gordon Wetzstein" target="_blank"
                data-tippy-content="See all papers authored by Gordon Wetzstein"
                class="text-muted filterByAuthorLink">Gordon Wetzstein</a>,
            
            <a href="papers.html?author=Michael Zollhoefer" target="_blank"
                data-tippy-content="See all papers authored by Michael Zollhoefer"
                class="text-muted filterByAuthorLink">Michael Zollhoefer</a>,
            
            <a href="papers.html?author=Vladislav Golyanik" target="_blank"
                data-tippy-content="See all papers authored by Vladislav Golyanik"
                class="text-muted filterByAuthorLink">Vladislav Golyanik</a>
            
        </h3>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            11/10/2021
        </h3>
        <div id="citation-code-wrapper" class="text-muted text-center"
        >
        </div>
        <p class="text-center" style="margin-bottom: 0px;">
            <span>Keywords:</span>
            
            <a href="papers.html?keyword=2D Image Neural Fields" target="_blank"
                data-tippy-content="See all papers with keyword '2D Image Neural Fields'"
                class="text-secondary text-decoration-none filterByKeywordLink">2D Image Neural Fields</a>,
            
            <a href="papers.html?keyword=Image-Based Rendering" target="_blank"
                data-tippy-content="See all papers with keyword 'Image-Based Rendering'"
                class="text-secondary text-decoration-none filterByKeywordLink">Image-Based Rendering</a>
            
        </p>

        
        <p class="text-center" style="margin-bottom: 0px;">
            <span>Venue: </span>
            <a href="papers.html?venue=ARXIV" target="_blank" class="text-secondary text-decoration-none">ARXIV 2021</a>
        </p>
        

        <div class="text-center p-3">
            <a class="card-link red-hyper-link" target="_blank" href="https://arxiv.org/pdf/2111.05849.pdf">
                Paper
            </a>
            
            <a class="card-link red-hyper-link" data-toggle="collapse" role="button" href="#citation">
                Citation
            </a>
            
            
            
        </div>
    </div>
    <span id="invisible-paper-id" style="display: none;">271</span>
</div>
<div id="citation" class="pp-card m-3 collapse">
    <div class="card-body">
        <div class="card-text">
            <span style="font-size: large; font-weight: bold;">Bibtex:</span>
            <span style="white-space: pre-line; position: relative; left: 20px;">
                @article{tewari2021advances,
    author = {Ayush Tewari and Justus Thies and Ben Mildenhall and Pratul Srinivasan and Edgar Tretschk and Yifan Wang and Christoph Lassner and Vincent Sitzmann and Ricardo Martin-Brualla and Stephen Lombardi and Tomas Simon and Christian Theobalt and Matthias Niessner and Jonathan T. Barron and Gordon Wetzstein and Michael Zollhoefer and Vladislav Golyanik},
    title = {Advances in Neural Rendering},
    year = {2021},
    month = {Nov},
    url = {http://arxiv.org/abs/2111.05849v1},
    entrytype = {article},
    id = {tewari2021advances}
}
            </span>
        </div>
        <p></p>
    </div>
</div>
<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <p style="font-weight: bolder; font-size: 25px; text-align: center;">Abstract</p>
                Synthesizing photo-realistic images and videos is at the heart of computer graphics and has been the focus of decades of research. Traditionally, synthetic images of a scene are generated using rendering algorithms such as rasterization or ray tracing, which take specifically defined representations of geometry and material properties as input. Collectively, these inputs define the actual scene and what is rendered, and are referred to as the scene representation (where a scene consists of one or more objects). Example scene representations are triangle meshes with accompanied textures (e.g., created by an artist), point clouds (e.g., from a depth sensor), volumetric grids (e.g., from a CT scan), or implicit surface functions (e.g., truncated signed distance fields). The reconstruction of such a scene representation from observations using differentiable rendering losses is known as inverse graphics or inverse rendering. Neural rendering is closely related, and combines ideas from classical computer graphics and machine learning to create algorithms for synthesizing images from real-world observations. Neural rendering is a leap forward towards the goal of synthesizing photo-realistic image and video content. In recent years, we have seen immense progress in this field through hundreds of publications that show different ways to inject learnable components into the rendering pipeline. This state-of-the-art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene. In addition to methods that handle static scenes, we cover neural scene representations for modeling non-rigidly deforming objects...
            </div>
        </div>
        <p></p>
    </div>
</div>

<!-- Youtube Video -->


<!-- Project Webpage -->


<!-- Citation Graph -->
<div class="border-top my-3"></div>
<div class="row p-4">
  <div class="col-12" style="text-align: center;">
    <span style="font-size: 25px;">Citation Graph</span> <br>
    <span>(Double click on nodes to open corresponding papers' pages)</span>
  </div>
</div>

<div id="citationGraph" style="width: 100%;
  height: 600px;
  border: 1px solid lightgray;" ondblclick="openPaperLink()"></div>
<p><span style="font-size: 10px;">*</span> Showing citation graph for papers within our database. Data retrieved from <a href="https://www.semanticscholar.org/search?q=Advances in Neural Rendering&sort=relevance">Semantic Scholar</a>. For full citation graphs, visit <a href="https://www.connectedpapers.com/search?q=Advances in Neural Rendering">ConnectedPapers</a>.</p>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script>
<script src="static/js/views/paper_detail.js"></script>
<script>
    tippy(".filterByAuthorLink");
    tippy(".filterByKeywordLink");
    const paperID = document.getElementById("invisible-paper-id").innerHTML;
    drawCitationGraphAndGenerateCitationCode(paperID);
</script>


      </div>
    </div>

    <!-- body block ends here-->
    


    


    <!-- Footer -->
    <footer class="footer"
      style="background-color: #353535; width: 100%; height: 8vh; display: flex; justify-content: center; align-items: center; ">
      <a class="fas" style="cursor: pointer; margin-right: auto; padding-left: 10px;"
        href="https://twitter.com/neural_fields" target="_blank">
        <img src="static/images/twitter_logo.png" style="width: 30px; height: 24px;">
      </a>
      <a href="https://visual.cs.brown.edu/" target="_blank"><img src="static/images/Brown_logo.png"
    style="height: 6vh; padding-right: 1vw;"></a>
      <a href="http://www.scenerepresentations.org/" target="_blank"><img src="static/images/MIT_logo.png" style="height: 2.7vh"></a>
      <a style="color: white; margin-left: auto; padding-right: 10px;" href="mailto:neuralfields@brown.edu"
        target="_blank">Contact Us</a>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (window.location.hash !== "") {
          $(`a[href="${window.location.hash}"]`).tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          const hash = $(e.target).attr("href");
          if (hash.substr(0, 1) === "#") {
            const position = $(window).scrollTop();
            window.location.replace(`#${hash.substr(1)}`);
            $(window).scrollTop(position);
          }
        });
      });
    </script>

    <!-- footer block ends here -->
    
  </body>

</html>