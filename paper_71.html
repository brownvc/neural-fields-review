

<!DOCTYPE html>
<html lang="en">

  <head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
      integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

    <script src="https://code.jquery.com/jquery-3.6.0.min.js"
      integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
      integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
      integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
      integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>


    <!-- Library libs_ext -->
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>

    <script src="static/js/tagEditor/jquery.caret.min.js"></script>
    <script src="static/js/tagEditor/jquery.tag-editor.min.js"></script>


    <!-- Internal Libs -->
    <script src="static/js/data/api.js"></script>

    <!-- External CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
      integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link href="static/css/Lato.css" rel="stylesheet" />
    <link href="static/css/Exo.css" rel="stylesheet" />
    <link href="static/css/Cuprum.css" rel="stylesheet" />
    <link rel="stylesheet" href="static/css/main.css" />
    <!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css" />
    <link rel="stylesheet" href="static/css/lazy_load.css" />
    <link rel="stylesheet" href="static/css/typeahead.css" />

    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/daterangepicker/daterangepicker.min.js"></script>
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/daterangepicker/daterangepicker.css" />

    <title>Neural Fields: LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration</title>

    <link rel="icon" type="image/png" href="favicon.ico">

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GT7LEVW06Z"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());

      gtag('config', 'G-GT7LEVW06Z');
    </script>
    <!-- head block ends here-->
    
<meta name="citation_title" content="LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration" />


<meta name="citation_author" content="Bharat Lal Bhatnagar" />

<meta name="citation_author" content="Cristian Sminchisescu" />

<meta name="citation_author" content="Christian Theobalt" />

<meta name="citation_author" content="Gerard Pons-Moll" />


<meta name="citation_abstract" content="We address the problem of fitting 3D human models to 3D scans of dressed humans. Classical methods optimize both the data-to-model correspondences and the human model parameters (pose and shape), but are reliable only when initialized close to the solution. Some methods initialize the optimization based on fully supervised correspondence predictors, which is not differentiable end-to-end, and can only process a single scan at a time. Our main contribution is LoopReg, an end-to-end learning framework to register a corpus of scans to a common 3D human model. The key idea is to create a self-supervised loop. A backward map, parameterized by a Neural Network, predicts the correspondence from every scan point to the surface of the human model. A forward map, parameterized by a human model, transforms the corresponding points back to the scan based on the model parameters (pose and shape), thus closing the loop. Formulating this closed loop is not straightforward because it is not trivial to force the output of the NN to be on the surface of the human model - outside this surface the human model is not even defined. To this end, we propose two key innovations. First, we define the canonical surface implicitly as the zero level set of a distance field in R3, which in contrast to morecommon UV parameterizations, does not require cutting the surface, does not have discontinuities, and does not induce distortion. Second, we diffuse the human model to the 3D domain R3. This allows to map the NN predictions forward,even when they slightly deviate from the zero level set. Results demonstrate that we can train LoopRegmainly self-supervised - following a supervised warm-start, the model becomes increasingly more accurate as additional unlabelled raw scans are processed. Our code and pre-trained models can be downloaded for research." />


<meta name="citation_keywords" content="Human (Body)" />

<meta name="citation_pdf_url" content="https://arxiv.org/pdf/2010.12447.pdf" />

<script type="text/javascript" src="static/js/vis/vis-network.min.js"></script>
<style>
    .red-hyper-link {
        color: #ED1C24 !important;
    }
</style>

  </head>

  <body>
    <!-- NAV -->
    
    <nav class="navbar sticky-top navbar-expand-lg navbar-light" style="background-color: #EFECE5;" id="main-nav">
      <div class="container">
        <a class="navbar-brand" href="index.html">
          <img class="logo" src="static/images/long_logo.png" style="width: 300px;"/>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
          aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
          <ul class="navbar-nav ml-auto">
            
            <li class="nav-item ">
              <a class="nav-link" href="index.html" style="font-family: 'Ubuntu', sans-serif;">Home</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="papers.html" style="font-family: 'Ubuntu', sans-serif;">Advanced Search</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="add_paper.html" style="font-family: 'Ubuntu', sans-serif;">Add Paper</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="join_us.html" style="font-family: 'Ubuntu', sans-serif;">Join Us</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="faq.html" style="font-family: 'Ubuntu', sans-serif;">FAQ</a>
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
    

    
    <!-- User Overrides -->

    
    <!-- top block ends here-->
    

    <div class="container">
      <!-- Tabs -->
      <div class="tabs">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3">
    <div class="card-header">
        <h2 class="card-title main-title text-center" style="color: black;">
            LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?author=Bharat Lal Bhatnagar" target="_blank"
                data-tippy-content="See all papers authored by Bharat Lal Bhatnagar"
                class="text-muted filterByAuthorLink">Bharat Lal Bhatnagar</a>,
            
            <a href="papers.html?author=Cristian Sminchisescu" target="_blank"
                data-tippy-content="See all papers authored by Cristian Sminchisescu"
                class="text-muted filterByAuthorLink">Cristian Sminchisescu</a>,
            
            <a href="papers.html?author=Christian Theobalt" target="_blank"
                data-tippy-content="See all papers authored by Christian Theobalt"
                class="text-muted filterByAuthorLink">Christian Theobalt</a>,
            
            <a href="papers.html?author=Gerard Pons-Moll" target="_blank"
                data-tippy-content="See all papers authored by Gerard Pons-Moll"
                class="text-muted filterByAuthorLink">Gerard Pons-Moll</a>
            
        </h3>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            10/23/2020
        </h3>
        <div id="citation-code-wrapper" class="text-muted text-center"
        >
        </div>
        <p class="text-center" style="margin-bottom: 0px;">
            <span>Keywords:</span>
            
            <a href="papers.html?keyword=Human (Body)" target="_blank"
                data-tippy-content="See all papers with keyword 'Human (Body)'"
                class="text-secondary text-decoration-none filterByKeywordLink">Human (Body)</a>
            
        </p>

        
        <p class="text-center" style="margin-bottom: 0px;">
            <span>Venue: </span>
            <a href="papers.html?venue=NeurIPS" target="_blank" class="text-secondary text-decoration-none">NeurIPS 2020</a>
        </p>
        

        <div class="text-center p-3">
            <a class="card-link red-hyper-link" target="_blank" href="https://arxiv.org/pdf/2010.12447.pdf">
                Paper
            </a>
            
            <a class="card-link red-hyper-link" data-toggle="collapse" role="button" href="#citation">
                Citation
            </a>
            
            
            <a href="https://github.com/bharat-b7/LoopReg" target="_blank" class="card-link red-hyper-link">
                Code
            </a>
            
            
        </div>
    </div>
    <span id="invisible-paper-id" style="display: none;">71</span>
</div>
<div id="citation" class="pp-card m-3 collapse">
    <div class="card-body">
        <div class="card-text">
            <span style="font-size: large; font-weight: bold;">Bibtex:</span>
            <span style="white-space: pre-line; position: relative; left: 20px;">
                @inproceedings{bhatnagar2020loopreg,
    publisher = {Curran Associates, Inc.},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    author = {Bharat Lal Bhatnagar and Cristian Sminchisescu and Christian Theobalt and Gerard Pons-Moll},
    title = {LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration},
    year = {2020},
    url = {http://arxiv.org/abs/2010.12447v1},
    entrytype = {inproceedings},
    id = {bhatnagar2020loopreg}
}
            </span>
        </div>
        <p></p>
    </div>
</div>
<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <p style="font-weight: bolder; font-size: 25px; text-align: center;">Abstract</p>
                We address the problem of fitting 3D human models to 3D scans of dressed humans. Classical methods optimize both the data-to-model correspondences and the human model parameters (pose and shape), but are reliable only when initialized close to the solution. Some methods initialize the optimization based on fully supervised correspondence predictors, which is not differentiable end-to-end, and can only process a single scan at a time. Our main contribution is LoopReg, an end-to-end learning framework to register a corpus of scans to a common 3D human model. The key idea is to create a self-supervised loop. A backward map, parameterized by a Neural Network, predicts the correspondence from every scan point to the surface of the human model. A forward map, parameterized by a human model, transforms the corresponding points back to the scan based on the model parameters (pose and shape), thus closing the loop. Formulating this closed loop is not straightforward because it is not trivial to force the output of the NN to be on the surface of the human model - outside this surface the human model is not even defined. To this end, we propose two key innovations. First, we define the canonical surface implicitly as the zero level set of a distance field in R3, which in contrast to morecommon UV parameterizations, does not require cutting the surface, does not have discontinuities, and does not induce distortion. Second, we diffuse the human model to the 3D domain R3. This allows to map the NN predictions forward,even when they slightly deviate from the zero level set. Results demonstrate that we can train LoopRegmainly self-supervised - following a supervised warm-start, the model becomes increasingly more accurate as additional unlabelled raw scans are processed. Our code and pre-trained models can be downloaded for research.
            </div>
        </div>
        <p></p>
    </div>
</div>

<!-- Youtube Video -->

<div class="border-top my-3"></div>
<div class="row p-4">
  <div class="col-12" style="text-align: center;">
    <a style="font-size: 25px; color: #ED1C24;" target="_blank" href="https://www.youtube.com/embed/fIhm_tWG_X8" >Video</a>
  </div>
</div>
<div class="col-md-12 col-xs-12 p-2">
    <iframe style="width: 100%; height: 60vh;" src="https://www.youtube.com/embed/fIhm_tWG_X8">
    </iframe>
</div>



<!-- Project Webpage -->


<!-- Citation Graph -->
<div class="border-top my-3"></div>
<div class="row p-4">
  <div class="col-12" style="text-align: center;">
    <span style="font-size: 25px;">Citation Graph</span> <br>
    <span>(Double click on nodes to open corresponding papers' pages)</span>
  </div>
</div>

<div id="citationGraph" style="width: 100%;
  height: 600px;
  border: 1px solid lightgray;" ondblclick="openPaperLink()"></div>
<p><span style="font-size: 10px;">*</span> Showing citation graph for papers within our database. Data retrieved from <a href="https://www.semanticscholar.org/search?q=LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration&sort=relevance">Semantic Scholar</a>. For full citation graphs, visit <a href="https://www.connectedpapers.com/search?q=LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration">ConnectedPapers</a>.</p>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script>
<script src="static/js/views/paper_detail.js"></script>
<script>
    tippy(".filterByAuthorLink");
    tippy(".filterByKeywordLink");
    const paperID = document.getElementById("invisible-paper-id").innerHTML;
    drawCitationGraphAndGenerateCitationCode(paperID);
</script>


      </div>
    </div>

    <!-- body block ends here-->
    


    


    <!-- Footer -->
    <footer class="footer"
      style="background-color: #353535; width: 100%; height: 8vh; display: flex; justify-content: center; align-items: center; ">
      <a class="fas" style="cursor: pointer; margin-right: auto; padding-left: 10px;"
        href="https://twitter.com/neural_fields" target="_blank">
        <img src="static/images/twitter_logo.png" style="width: 30px; height: 24px;">
      </a>
      <a href="https://visual.cs.brown.edu/" target="_blank"><img src="static/images/Brown_logo.png"
    style="height: 6vh; padding-right: 1vw;"></a>
      <a href="http://www.scenerepresentations.org/" target="_blank"><img src="static/images/MIT_logo.png" style="height: 2.7vh"></a>
      <a style="color: white; margin-left: auto; padding-right: 10px;" href="mailto:neuralfields@brown.edu"
        target="_blank">Contact Us</a>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (window.location.hash !== "") {
          $(`a[href="${window.location.hash}"]`).tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          const hash = $(e.target).attr("href");
          if (hash.substr(0, 1) === "#") {
            const position = $(window).scrollTop();
            window.location.replace(`#${hash.substr(1)}`);
            $(window).scrollTop(position);
          }
        });
      });
    </script>

    <!-- footer block ends here -->
    
  </body>

</html>