

<!DOCTYPE html>
<html lang="en">

  <head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
      integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

    <script src="https://code.jquery.com/jquery-3.6.0.min.js"
      integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
      integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
      integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
      integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>


    <!-- Library libs_ext -->
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>

    <script src="static/js/tagEditor/jquery.caret.min.js"></script>
    <script src="static/js/tagEditor/jquery.tag-editor.min.js"></script>


    <!-- Internal Libs -->
    <script src="static/js/data/api.js"></script>

    <!-- External CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
      integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link href="static/css/Lato.css" rel="stylesheet" />
    <link href="static/css/Exo.css" rel="stylesheet" />
    <link href="static/css/Cuprum.css" rel="stylesheet" />
    <link rel="stylesheet" href="static/css/main.css" />
    <!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css" />
    <link rel="stylesheet" href="static/css/lazy_load.css" />
    <link rel="stylesheet" href="static/css/typeahead.css" />

    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/daterangepicker/daterangepicker.min.js"></script>
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/daterangepicker/daterangepicker.css" />

    <title>Neural Fields: Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes</title>

    <link rel="icon" type="image/png" href="favicon.ico">

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GT7LEVW06Z"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());

      gtag('config', 'G-GT7LEVW06Z');
    </script>
    <!-- head block ends here-->
    
<meta name="citation_title" content="Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes" />


<meta name="citation_author" content="Julian Chibane" />

<meta name="citation_author" content="Aayush Bansal" />

<meta name="citation_author" content="Verica Lazova" />

<meta name="citation_author" content="Gerard Pons-Moll" />


<meta name="citation_abstract" content="Recent neural view synthesis methods have achieved impressive quality and realism, surpassing classical pipelines which rely on multi-view reconstruction. State-of-the-Art methods, such as NeRF, are designed to learn a single scene with a neural network and require dense multi-view inputs. Testing on a new scene requires re-training from scratch, which takes 2-3 days. In this work, we introduce Stereo Radiance Fields (SRF), a neural view synthesis approach that is trained end-to-end, generalizes to new scenes, and requires only sparse views at test time. The core idea is a neural architecture inspired by classical multi-view stereo methods, which estimates surface points by finding similar image regions in stereo images. In SRF, we predict color and density for each 3D point given an encoding of its stereo correspondence in the input images. The encoding is implicitly learned by an ensemble of pair-wise similarities -- emulating classical stereo. Experiments show that SRF learns structure instead of overfitting on a scene. We train on multiple scenes of the DTU dataset and generalize to new ones without re-training, requiring only 10 sparse and spread-out views as input. We show that 10-15 minutes of fine-tuning further improve the results, achieving significantly sharper, more detailed results than scene-specific models. The code, model, and videos are available at https://virtualhumans.mpi-inf.mpg.de/srf/." />


<meta name="citation_keywords" content="Speed &amp; Computational Efficiency" />

<meta name="citation_keywords" content="Sparse Reconstruction" />

<meta name="citation_keywords" content="Generalization" />

<meta name="citation_keywords" content="Image-Based Rendering" />

<meta name="citation_keywords" content="Local Conditioning" />

<meta name="citation_pdf_url" content="https://arxiv.org/pdf/2104.06935.pdf" />

<script type="text/javascript" src="static/js/vis/vis-network.min.js"></script>
<style>
    .red-hyper-link {
        color: #ED1C24 !important;
    }
</style>

  </head>

  <body>
    <!-- NAV -->
    
    <nav class="navbar sticky-top navbar-expand-lg navbar-light" style="background-color: #EFECE5;" id="main-nav">
      <div class="container">
        <a class="navbar-brand" href="index.html">
          <img class="logo" src="static/images/long_logo.png" style="width: 300px;"/>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
          aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
          <ul class="navbar-nav ml-auto">
            
            <li class="nav-item ">
              <a class="nav-link" href="index.html" style="font-family: 'Ubuntu', sans-serif;">Home</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="papers.html" style="font-family: 'Ubuntu', sans-serif;">Advanced Search</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="add_paper.html" style="font-family: 'Ubuntu', sans-serif;">Add Paper</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="join_us.html" style="font-family: 'Ubuntu', sans-serif;">Join Us</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="faq.html" style="font-family: 'Ubuntu', sans-serif;">FAQ</a>
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
    

    
    <!-- User Overrides -->

    
    <!-- top block ends here-->
    

    <div class="container">
      <!-- Tabs -->
      <div class="tabs">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3">
    <div class="card-header">
        <h2 class="card-title main-title text-center" style="color: black;">
            Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?author=Julian Chibane" target="_blank"
                data-tippy-content="See all papers authored by Julian Chibane"
                class="text-muted filterByAuthorLink">Julian Chibane</a>,
            
            <a href="papers.html?author=Aayush Bansal" target="_blank"
                data-tippy-content="See all papers authored by Aayush Bansal"
                class="text-muted filterByAuthorLink">Aayush Bansal</a>,
            
            <a href="papers.html?author=Verica Lazova" target="_blank"
                data-tippy-content="See all papers authored by Verica Lazova"
                class="text-muted filterByAuthorLink">Verica Lazova</a>,
            
            <a href="papers.html?author=Gerard Pons-Moll" target="_blank"
                data-tippy-content="See all papers authored by Gerard Pons-Moll"
                class="text-muted filterByAuthorLink">Gerard Pons-Moll</a>
            
        </h3>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            4/14/2021
        </h3>
        <div id="citation-code-wrapper" class="text-muted text-center"
        >
        </div>
        <p class="text-center" style="margin-bottom: 0px;">
            <span>Keywords:</span>
            
            <a href="papers.html?keyword=Speed &amp; Computational Efficiency" target="_blank"
                data-tippy-content="See all papers with keyword 'Speed &amp; Computational Efficiency'"
                class="text-secondary text-decoration-none filterByKeywordLink">Speed &amp; Computational Efficiency</a>,
            
            <a href="papers.html?keyword=Sparse Reconstruction" target="_blank"
                data-tippy-content="See all papers with keyword 'Sparse Reconstruction'"
                class="text-secondary text-decoration-none filterByKeywordLink">Sparse Reconstruction</a>,
            
            <a href="papers.html?keyword=Generalization" target="_blank"
                data-tippy-content="See all papers with keyword 'Generalization'"
                class="text-secondary text-decoration-none filterByKeywordLink">Generalization</a>,
            
            <a href="papers.html?keyword=Image-Based Rendering" target="_blank"
                data-tippy-content="See all papers with keyword 'Image-Based Rendering'"
                class="text-secondary text-decoration-none filterByKeywordLink">Image-Based Rendering</a>,
            
            <a href="papers.html?keyword=Local Conditioning" target="_blank"
                data-tippy-content="See all papers with keyword 'Local Conditioning'"
                class="text-secondary text-decoration-none filterByKeywordLink">Local Conditioning</a>
            
        </p>

        
        <p class="text-center" style="margin-bottom: 0px;">
            <span>Venue: </span>
            <a href="papers.html?venue=CVPR" target="_blank" class="text-secondary text-decoration-none">CVPR 2021</a>
        </p>
        

        <div class="text-center p-3">
            <a class="card-link red-hyper-link" target="_blank" href="https://arxiv.org/pdf/2104.06935.pdf">
                Paper
            </a>
            
            <a class="card-link red-hyper-link" data-toggle="collapse" role="button" href="#citation">
                Citation
            </a>
            
            
            
        </div>
    </div>
    <span id="invisible-paper-id" style="display: none;">163</span>
</div>
<div id="citation" class="pp-card m-3 collapse">
    <div class="card-body">
        <div class="card-text">
            <span style="font-size: large; font-weight: bold;">Bibtex:</span>
            <span style="white-space: pre-line; position: relative; left: 20px;">
                @inproceedings{chibane2021srf,
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    author = {Julian Chibane and Aayush Bansal and Verica Lazova and Gerard Pons-Moll},
    title = {Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes},
    year = {2021},
    url = {http://arxiv.org/abs/2104.06935v1},
    entrytype = {inproceedings},
    id = {chibane2021srf}
}
            </span>
        </div>
        <p></p>
    </div>
</div>
<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <p style="font-weight: bolder; font-size: 25px; text-align: center;">Abstract</p>
                Recent neural view synthesis methods have achieved impressive quality and realism, surpassing classical pipelines which rely on multi-view reconstruction. State-of-the-Art methods, such as NeRF, are designed to learn a single scene with a neural network and require dense multi-view inputs. Testing on a new scene requires re-training from scratch, which takes 2-3 days. In this work, we introduce Stereo Radiance Fields (SRF), a neural view synthesis approach that is trained end-to-end, generalizes to new scenes, and requires only sparse views at test time. The core idea is a neural architecture inspired by classical multi-view stereo methods, which estimates surface points by finding similar image regions in stereo images. In SRF, we predict color and density for each 3D point given an encoding of its stereo correspondence in the input images. The encoding is implicitly learned by an ensemble of pair-wise similarities -- emulating classical stereo. Experiments show that SRF learns structure instead of overfitting on a scene. We train on multiple scenes of the DTU dataset and generalize to new ones without re-training, requiring only 10 sparse and spread-out views as input. We show that 10-15 minutes of fine-tuning further improve the results, achieving significantly sharper, more detailed results than scene-specific models. The code, model, and videos are available at https://virtualhumans.mpi-inf.mpg.de/srf/.
            </div>
        </div>
        <p></p>
    </div>
</div>

<!-- Youtube Video -->


<!-- Project Webpage -->

<div class="border-top my-3"></div>
<div class="row p-4">
  <div class="col-12" style="text-align: center;">
    <a style="font-size: 25px; color: #ED1C24;" target="_blank" href="https://virtualhumans.mpi-inf.mpg.de/srf/" >Project Webpage</a>
  </div>
</div>
<div class="col-md-12 col-xs-12 p-2">
    <iframe style="width: 100%; height: 60vh;" src="https://virtualhumans.mpi-inf.mpg.de/srf/">
    </iframe>
</div>



<!-- Citation Graph -->
<div class="border-top my-3"></div>
<div class="row p-4">
  <div class="col-12" style="text-align: center;">
    <span style="font-size: 25px;">Citation Graph</span> <br>
    <span>(Double click on nodes to open corresponding papers' pages)</span>
  </div>
</div>

<div id="citationGraph" style="width: 100%;
  height: 600px;
  border: 1px solid lightgray;" ondblclick="openPaperLink()"></div>
<p><span style="font-size: 10px;">*</span> Showing citation graph for papers within our database. Data retrieved from <a href="https://www.semanticscholar.org/search?q=Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes&sort=relevance">Semantic Scholar</a>. For full citation graphs, visit <a href="https://www.connectedpapers.com/search?q=Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes">ConnectedPapers</a>.</p>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script>
<script src="static/js/views/paper_detail.js"></script>
<script>
    tippy(".filterByAuthorLink");
    tippy(".filterByKeywordLink");
    const paperID = document.getElementById("invisible-paper-id").innerHTML;
    drawCitationGraphAndGenerateCitationCode(paperID);
</script>


      </div>
    </div>

    <!-- body block ends here-->
    


    


    <!-- Footer -->
    <footer class="footer"
      style="background-color: #353535; width: 100%; height: 8vh; display: flex; justify-content: center; align-items: center; ">
      <a class="fas" style="cursor: pointer; margin-right: auto; padding-left: 10px;"
        href="https://twitter.com/neural_fields" target="_blank">
        <img src="static/images/twitter_logo.png" style="width: 30px; height: 24px;">
      </a>
      <a href="https://visual.cs.brown.edu/" target="_blank"><img src="static/images/Brown_logo.png"
    style="height: 6vh; padding-right: 1vw;"></a>
      <a href="http://www.scenerepresentations.org/" target="_blank"><img src="static/images/MIT_logo.png" style="height: 2.7vh"></a>
      <a style="color: white; margin-left: auto; padding-right: 10px;" href="mailto:neuralfields@brown.edu"
        target="_blank">Contact Us</a>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (window.location.hash !== "") {
          $(`a[href="${window.location.hash}"]`).tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          const hash = $(e.target).attr("href");
          if (hash.substr(0, 1) === "#") {
            const position = $(window).scrollTop();
            window.location.replace(`#${hash.substr(1)}`);
            $(window).scrollTop(position);
          }
        });
      });
    </script>

    <!-- footer block ends here -->
    
  </body>

</html>